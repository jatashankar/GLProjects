{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5976,"status":"ok","timestamp":1716719758134,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"},"user_tz":-330},"id":"tVlDA4ib7Ho7"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.metrics import accuracy_score,classification_report, roc_auc_score, confusion_matrix\n","from sklearn.preprocessing import PolynomialFeatures\n","from imblearn.over_sampling import SMOTE"]},{"cell_type":"markdown","metadata":{"id":"AjuML6Wh-Xzh"},"source":["# Load Data\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5149,"status":"ok","timestamp":1716719767138,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"},"user_tz":-330},"id":"U7Kzu88R-pV5"},"outputs":[],"source":["# Load train and test data\n","train_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/GreatLearning/Hackahon/Hackathon_25May2024/Train_set_(1)_(1).csv')\n","test_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/GreatLearning/Hackahon/Hackathon_25May2024/Test_set_(1)_(2).csv')\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1716702754058,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"},"user_tz":-330},"id":"nuTnTnmg_I1h","outputId":"b34dd287-651e-406b-9b39-87d2138cc426"},"outputs":[{"output_type":"stream","name":"stdout","text":["Inspect the data in train data:\n","          ID  loan_amnt loan_term  interest_rate loan_grade loan_subgrade  \\\n","0  72199369       9000   3 years           9.17          B            B2   \n","1  14257956      18000   3 years          13.65          C            C1   \n","2  66216451      16000   3 years           7.26          A            A4   \n","3  46974169      25000   3 years          13.99          C            C4   \n","4  46725961      17000   3 years           6.39          A            A2   \n","\n","  job_experience home_ownership  annual_income income_verification_status  \\\n","0       <5 Years            OWN        85000.0               Not Verified   \n","1       <5 Years            OWN        64000.0                   Verified   \n","2       <5 Years       MORTGAGE       150000.0            Source Verified   \n","3            NaN       MORTGAGE        59800.0                   Verified   \n","4      10+ years       MORTGAGE        72000.0            Source Verified   \n","\n","   ... delinq_2yrs public_records  revolving_balance  total_acc  \\\n","0  ...         0.0            0.0              39519       20.0   \n","1  ...         0.0            1.0               9783       24.0   \n","2  ...         2.0            0.0              13641       27.0   \n","3  ...         0.0            0.0              35020       35.0   \n","4  ...         0.0            0.0              23990       26.0   \n","\n","   interest_receive  application_type  last_week_pay  total_current_balance  \\\n","0             59.60        INDIVIDUAL            4.0                95493.0   \n","1           3348.25        INDIVIDUAL           95.0               185433.0   \n","2            276.69        INDIVIDUAL           13.0               180519.0   \n","3           1106.72        INDIVIDUAL           17.0               183208.0   \n","4            725.29        INDIVIDUAL           39.0                23990.0   \n","\n","  total_revolving_limit  default  \n","0               84100.0        0  \n","1               13500.0        0  \n","2               19300.0        0  \n","3               55400.0        0  \n","4               81300.0        0  \n","\n","[5 rows x 23 columns]\n","\n","Inspect the data in test data:\n","          ID  loan_amnt loan_term  interest_rate loan_grade loan_subgrade  \\\n","0   4855329      12000   3 years          15.31          C            C2   \n","1  66862420      12000   3 years           7.26          A            A4   \n","2   3637416      15000   3 years          14.33          C            C1   \n","3  53682249      12000   3 years           9.99          B            B3   \n","4  53937165      20150   3 years          11.53          B            B5   \n","\n","  job_experience home_ownership  annual_income income_verification_status  \\\n","0       <5 Years       MORTGAGE        73400.0               Not Verified   \n","1      10+ years       MORTGAGE       105000.0               Not Verified   \n","2     6-10 years       MORTGAGE        50000.0                   Verified   \n","3     6-10 years           RENT        37000.0            Source Verified   \n","4       <5 Years           RENT        75000.0            Source Verified   \n","\n","   ... debt_to_income delinq_2yrs  public_records  revolving_balance  \\\n","0  ...          14.62         0.0             0.0              22156   \n","1  ...          11.38         0.0             0.0               7592   \n","2  ...          28.15         0.0             1.0              17983   \n","3  ...          34.32         0.0             0.0              12262   \n","4  ...          26.74         1.0             0.0               8251   \n","\n","   total_acc  interest_receive  application_type  last_week_pay  \\\n","0       30.0           2290.24        INDIVIDUAL           87.0   \n","1       14.0            202.68        INDIVIDUAL           13.0   \n","2       19.0           1166.24        INDIVIDUAL           30.0   \n","3       18.0            635.06        INDIVIDUAL           35.0   \n","4       11.0           1232.84        INDIVIDUAL           31.0   \n","\n","  total_current_balance  total_revolving_limit  \n","0              128098.0                25800.0  \n","1              269396.0                23600.0  \n","2              220135.0                34100.0  \n","3               39436.0                21700.0  \n","4               52764.0                12000.0  \n","\n","[5 rows x 22 columns]\n"]}],"source":["# Inspect the data\n","print(\"Inspect the data in train data:\\n\", train_data.head())\n","print(\"\\nInspect the data in test data:\\n\", test_data.head())\n"]},{"cell_type":"markdown","metadata":{"id":"Wjrgyhoq_wTC"},"source":["# Exploratory Data Analysis (EDA)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1716702754058,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"},"user_tz":-330},"id":"2Wi4M9EyAOhJ"},"outputs":[],"source":["# Check for missing values in train and test data\n","missing_values_train = train_data.isnull().sum()\n","missing_values_test = test_data.isnull().sum()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1716702754058,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"},"user_tz":-330},"id":"fd3Ygp6-_22J","outputId":"5336fb5c-7bcb-4111-ebe8-733c04018ebc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Missing values in train data:\n"," ID                               0\n","loan_amnt                        0\n","loan_term                        0\n","interest_rate                    0\n","loan_grade                       0\n","loan_subgrade                    0\n","job_experience                4702\n","home_ownership                   0\n","annual_income                    1\n","income_verification_status       0\n","loan_purpose                     0\n","state_code                       0\n","debt_to_income                   0\n","delinq_2yrs                      2\n","public_records                   2\n","revolving_balance                0\n","total_acc                        2\n","interest_receive                 0\n","application_type                 0\n","last_week_pay                 1924\n","total_current_balance         7386\n","total_revolving_limit         7386\n","default                          0\n","dtype: int64\n","\n","Missing values in test data:\n"," ID                               0\n","loan_amnt                        0\n","loan_term                        0\n","interest_rate                    0\n","loan_grade                       0\n","loan_subgrade                    0\n","job_experience                2089\n","home_ownership                   0\n","annual_income                    0\n","income_verification_status       0\n","loan_purpose                     0\n","state_code                       0\n","debt_to_income                   0\n","delinq_2yrs                      1\n","public_records                   1\n","revolving_balance                0\n","total_acc                        1\n","interest_receive                 0\n","application_type                 0\n","last_week_pay                  806\n","total_current_balance         3230\n","total_revolving_limit         3230\n","dtype: int64\n"]}],"source":["print(\"Missing values in train data:\\n\", missing_values_train)\n","print(\"\\nMissing values in test data:\\n\", missing_values_test)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1716702754059,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"},"user_tz":-330},"id":"dy03ha6nA52H","outputId":"0d9091ac-2ae2-4ae2-9b56-f4429b16e29d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["ID                              int64\n","loan_amnt                       int64\n","loan_term                      object\n","interest_rate                 float64\n","loan_grade                     object\n","loan_subgrade                  object\n","job_experience                 object\n","home_ownership                 object\n","annual_income                 float64\n","income_verification_status     object\n","loan_purpose                   object\n","state_code                     object\n","debt_to_income                float64\n","delinq_2yrs                   float64\n","public_records                float64\n","revolving_balance               int64\n","total_acc                     float64\n","interest_receive              float64\n","application_type               object\n","last_week_pay                 float64\n","total_current_balance         float64\n","total_revolving_limit         float64\n","default                         int64\n","dtype: object"]},"metadata":{},"execution_count":7}],"source":["train_data.dtypes"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":541,"status":"ok","timestamp":1716719780235,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"},"user_tz":-330},"id":"2jH7Wz9VDE3I"},"outputs":[],"source":["# Identify numerical and categorical columns\n","numerical_cols = train_data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n","categorical_cols = train_data.select_dtypes(include=['object']).columns.tolist()\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1716702754059,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"},"user_tz":-330},"id":"G8t5rUbCDHgX","outputId":"ce6ee1df-1887-4153-f826-da3f6019c965"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['ID',\n"," 'loan_amnt',\n"," 'interest_rate',\n"," 'annual_income',\n"," 'debt_to_income',\n"," 'delinq_2yrs',\n"," 'public_records',\n"," 'revolving_balance',\n"," 'total_acc',\n"," 'interest_receive',\n"," 'last_week_pay',\n"," 'total_current_balance',\n"," 'total_revolving_limit',\n"," 'default']"]},"metadata":{},"execution_count":9}],"source":["numerical_cols"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1716702754059,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"},"user_tz":-330},"id":"BdapwPphDOhn","outputId":"c59712e2-574c-495a-cc03-ede51470a294"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['loan_term',\n"," 'loan_grade',\n"," 'loan_subgrade',\n"," 'job_experience',\n"," 'home_ownership',\n"," 'income_verification_status',\n"," 'loan_purpose',\n"," 'state_code',\n"," 'application_type']"]},"metadata":{},"execution_count":10}],"source":["categorical_cols"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1716702754059,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"},"user_tz":-330},"id":"8Ac8Q7ehMsrw"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1716719784725,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"},"user_tz":-330},"id":"LH3tz3FeMsnC"},"outputs":[],"source":["# Remove target and ID columns from the list of features\n","numerical_cols.remove('default')\n","if 'ID' in numerical_cols:\n","    numerical_cols.remove('ID')\n","if 'ID' in categorical_cols:\n","    categorical_cols.remove('ID')"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1716719788383,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"},"user_tz":-330},"id":"BVvQGqzsMsju"},"outputs":[],"source":["# Preprocessing for numerical data\n","numerical_transformer = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='median')),  # Impute missing values with median\n","    ('scaler', StandardScaler())\n","])\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":731,"status":"ok","timestamp":1716719791391,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"},"user_tz":-330},"id":"b3-hwrJdMxfL"},"outputs":[],"source":["# Preprocessing for categorical data\n","categorical_transformer = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values with most frequent value\n","    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n","])"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1716719796062,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"},"user_tz":-330},"id":"mWfuQ_9LMxcJ"},"outputs":[],"source":["# Combine preprocessing steps\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numerical_transformer, numerical_cols),\n","        ('cat', categorical_transformer, categorical_cols)\n","    ])"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1716719799310,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"},"user_tz":-330},"id":"0WpkbMb0MxZA"},"outputs":[],"source":["# Split the train data into train and validation sets\n","X = train_data.drop(['ID', 'default'], axis=1)\n","y = train_data['default']\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"]},{"cell_type":"markdown","metadata":{"id":"8Xg7w8hYFFXa"},"source":["# Training the Model"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":634,"status":"ok","timestamp":1716702754683,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"},"user_tz":-330},"id":"hBwTUNSzMxV-"},"outputs":[],"source":["# Define the model\n","model = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n","])"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":231},"executionInfo":{"elapsed":199553,"status":"ok","timestamp":1716702954233,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"},"user_tz":-330},"id":"BYFUWGFoMxTG","outputId":"9832179a-2907-435b-acd5-c216b3030894"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(steps=[('preprocessor',\n","                 ColumnTransformer(transformers=[('num',\n","                                                  Pipeline(steps=[('imputer',\n","                                                                   SimpleImputer(strategy='median')),\n","                                                                  ('scaler',\n","                                                                   StandardScaler())]),\n","                                                  ['loan_amnt', 'interest_rate',\n","                                                   'annual_income',\n","                                                   'debt_to_income',\n","                                                   'delinq_2yrs',\n","                                                   'public_records',\n","                                                   'revolving_balance',\n","                                                   'total_acc',\n","                                                   'interest_receive',\n","                                                   'last_week_pay',\n","                                                   'total_current_balance',\n","                                                   'tot..._limit']),\n","                                                 ('cat',\n","                                                  Pipeline(steps=[('imputer',\n","                                                                   SimpleImputer(strategy='most_frequent')),\n","                                                                  ('onehot',\n","                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n","                                                  ['loan_term', 'loan_grade',\n","                                                   'loan_subgrade',\n","                                                   'job_experience',\n","                                                   'home_ownership',\n","                                                   'income_verification_status',\n","                                                   'loan_purpose', 'state_code',\n","                                                   'application_type'])])),\n","                ('classifier', RandomForestClassifier(random_state=42))])"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n","                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n","                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n","                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n","                                                                  (&#x27;scaler&#x27;,\n","                                                                   StandardScaler())]),\n","                                                  [&#x27;loan_amnt&#x27;, &#x27;interest_rate&#x27;,\n","                                                   &#x27;annual_income&#x27;,\n","                                                   &#x27;debt_to_income&#x27;,\n","                                                   &#x27;delinq_2yrs&#x27;,\n","                                                   &#x27;public_records&#x27;,\n","                                                   &#x27;revolving_balance&#x27;,\n","                                                   &#x27;total_acc&#x27;,\n","                                                   &#x27;interest_receive&#x27;,\n","                                                   &#x27;last_week_pay&#x27;,\n","                                                   &#x27;total_current_balance&#x27;,\n","                                                   &#x27;tot..._limit&#x27;]),\n","                                                 (&#x27;cat&#x27;,\n","                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n","                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n","                                                                  (&#x27;onehot&#x27;,\n","                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n","                                                  [&#x27;loan_term&#x27;, &#x27;loan_grade&#x27;,\n","                                                   &#x27;loan_subgrade&#x27;,\n","                                                   &#x27;job_experience&#x27;,\n","                                                   &#x27;home_ownership&#x27;,\n","                                                   &#x27;income_verification_status&#x27;,\n","                                                   &#x27;loan_purpose&#x27;, &#x27;state_code&#x27;,\n","                                                   &#x27;application_type&#x27;])])),\n","                (&#x27;classifier&#x27;, RandomForestClassifier(random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n","                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n","                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n","                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n","                                                                  (&#x27;scaler&#x27;,\n","                                                                   StandardScaler())]),\n","                                                  [&#x27;loan_amnt&#x27;, &#x27;interest_rate&#x27;,\n","                                                   &#x27;annual_income&#x27;,\n","                                                   &#x27;debt_to_income&#x27;,\n","                                                   &#x27;delinq_2yrs&#x27;,\n","                                                   &#x27;public_records&#x27;,\n","                                                   &#x27;revolving_balance&#x27;,\n","                                                   &#x27;total_acc&#x27;,\n","                                                   &#x27;interest_receive&#x27;,\n","                                                   &#x27;last_week_pay&#x27;,\n","                                                   &#x27;total_current_balance&#x27;,\n","                                                   &#x27;tot..._limit&#x27;]),\n","                                                 (&#x27;cat&#x27;,\n","                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n","                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n","                                                                  (&#x27;onehot&#x27;,\n","                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n","                                                  [&#x27;loan_term&#x27;, &#x27;loan_grade&#x27;,\n","                                                   &#x27;loan_subgrade&#x27;,\n","                                                   &#x27;job_experience&#x27;,\n","                                                   &#x27;home_ownership&#x27;,\n","                                                   &#x27;income_verification_status&#x27;,\n","                                                   &#x27;loan_purpose&#x27;, &#x27;state_code&#x27;,\n","                                                   &#x27;application_type&#x27;])])),\n","                (&#x27;classifier&#x27;, RandomForestClassifier(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n","                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n","                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n","                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n","                                 [&#x27;loan_amnt&#x27;, &#x27;interest_rate&#x27;, &#x27;annual_income&#x27;,\n","                                  &#x27;debt_to_income&#x27;, &#x27;delinq_2yrs&#x27;,\n","                                  &#x27;public_records&#x27;, &#x27;revolving_balance&#x27;,\n","                                  &#x27;total_acc&#x27;, &#x27;interest_receive&#x27;,\n","                                  &#x27;last_week_pay&#x27;, &#x27;total_current_balance&#x27;,\n","                                  &#x27;total_revolving_limit&#x27;]),\n","                                (&#x27;cat&#x27;,\n","                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n","                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n","                                                 (&#x27;onehot&#x27;,\n","                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n","                                 [&#x27;loan_term&#x27;, &#x27;loan_grade&#x27;, &#x27;loan_subgrade&#x27;,\n","                                  &#x27;job_experience&#x27;, &#x27;home_ownership&#x27;,\n","                                  &#x27;income_verification_status&#x27;, &#x27;loan_purpose&#x27;,\n","                                  &#x27;state_code&#x27;, &#x27;application_type&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;loan_amnt&#x27;, &#x27;interest_rate&#x27;, &#x27;annual_income&#x27;, &#x27;debt_to_income&#x27;, &#x27;delinq_2yrs&#x27;, &#x27;public_records&#x27;, &#x27;revolving_balance&#x27;, &#x27;total_acc&#x27;, &#x27;interest_receive&#x27;, &#x27;last_week_pay&#x27;, &#x27;total_current_balance&#x27;, &#x27;total_revolving_limit&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;loan_term&#x27;, &#x27;loan_grade&#x27;, &#x27;loan_subgrade&#x27;, &#x27;job_experience&#x27;, &#x27;home_ownership&#x27;, &#x27;income_verification_status&#x27;, &#x27;loan_purpose&#x27;, &#x27;state_code&#x27;, &#x27;application_type&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div>"]},"metadata":{},"execution_count":17}],"source":["# Train the model\n","model.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":705,"status":"ok","timestamp":1716702954932,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"},"user_tz":-330},"id":"ZDZwIB73I4Up","outputId":"448704f9-f2c3-48d3-a75f-d683c7d9300c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.820821035685538\n","              precision    recall  f1-score   support\n","\n","           0       0.81      0.99      0.89     14083\n","           1       0.89      0.30      0.45      4552\n","\n","    accuracy                           0.82     18635\n","   macro avg       0.85      0.65      0.67     18635\n","weighted avg       0.83      0.82      0.79     18635\n","\n","Confusion Matrix:\n"," [[13915   168]\n"," [ 3171  1381]]\n"]}],"source":["# Validate the model\n","y_val_pred = model.predict(X_val)\n","print('Accuracy:', accuracy_score(y_val, y_val_pred))\n","print(classification_report(y_val, y_val_pred))\n","print('Confusion Matrix:\\n', confusion_matrix(y_val, y_val_pred))"]},{"cell_type":"markdown","metadata":{"id":"nSHPW6LAJa2e"},"source":["# Hyperparameter Tuning"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1716702954934,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"},"user_tz":-330},"id":"2HMbx9ZdJp5v"},"outputs":[],"source":["param_grid = {\n","    'classifier__n_estimators': [100, 200, 300],\n","    'classifier__max_depth': [10, 20, 30]\n","}"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":257},"id":"Ym5Ql7LjJuQh","executionInfo":{"status":"ok","timestamp":1716710352814,"user_tz":-330,"elapsed":7397886,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"}},"outputId":"bd21d7d2-feb8-427e-cb29-25b5c5c03cfb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=5,\n","             estimator=Pipeline(steps=[('preprocessor',\n","                                        ColumnTransformer(transformers=[('num',\n","                                                                         Pipeline(steps=[('imputer',\n","                                                                                          SimpleImputer(strategy='median')),\n","                                                                                         ('scaler',\n","                                                                                          StandardScaler())]),\n","                                                                         ['loan_amnt',\n","                                                                          'interest_rate',\n","                                                                          'annual_income',\n","                                                                          'debt_to_income',\n","                                                                          'delinq_2yrs',\n","                                                                          'public_records',\n","                                                                          'revolving_balance',\n","                                                                          'total_acc',\n","                                                                          'interest_receive',\n","                                                                          'last_week_pay',...\n","                                                                                          OneHotEncoder(handle_unknown='ignore'))]),\n","                                                                         ['loan_term',\n","                                                                          'loan_grade',\n","                                                                          'loan_subgrade',\n","                                                                          'job_experience',\n","                                                                          'home_ownership',\n","                                                                          'income_verification_status',\n","                                                                          'loan_purpose',\n","                                                                          'state_code',\n","                                                                          'application_type'])])),\n","                                       ('classifier',\n","                                        RandomForestClassifier(random_state=42))]),\n","             param_grid={'classifier__max_depth': [10, 20, 30],\n","                         'classifier__n_estimators': [100, 200, 300]},\n","             scoring='accuracy')"],"text/html":["<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n","             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n","                                        ColumnTransformer(transformers=[(&#x27;num&#x27;,\n","                                                                         Pipeline(steps=[(&#x27;imputer&#x27;,\n","                                                                                          SimpleImputer(strategy=&#x27;median&#x27;)),\n","                                                                                         (&#x27;scaler&#x27;,\n","                                                                                          StandardScaler())]),\n","                                                                         [&#x27;loan_amnt&#x27;,\n","                                                                          &#x27;interest_rate&#x27;,\n","                                                                          &#x27;annual_income&#x27;,\n","                                                                          &#x27;debt_to_income&#x27;,\n","                                                                          &#x27;delinq_2yrs&#x27;,\n","                                                                          &#x27;public_records&#x27;,\n","                                                                          &#x27;revolving_balance&#x27;,\n","                                                                          &#x27;total_acc&#x27;,\n","                                                                          &#x27;interest_receive&#x27;,\n","                                                                          &#x27;last_week_pay&#x27;,...\n","                                                                                          OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n","                                                                         [&#x27;loan_term&#x27;,\n","                                                                          &#x27;loan_grade&#x27;,\n","                                                                          &#x27;loan_subgrade&#x27;,\n","                                                                          &#x27;job_experience&#x27;,\n","                                                                          &#x27;home_ownership&#x27;,\n","                                                                          &#x27;income_verification_status&#x27;,\n","                                                                          &#x27;loan_purpose&#x27;,\n","                                                                          &#x27;state_code&#x27;,\n","                                                                          &#x27;application_type&#x27;])])),\n","                                       (&#x27;classifier&#x27;,\n","                                        RandomForestClassifier(random_state=42))]),\n","             param_grid={&#x27;classifier__max_depth&#x27;: [10, 20, 30],\n","                         &#x27;classifier__n_estimators&#x27;: [100, 200, 300]},\n","             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n","             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n","                                        ColumnTransformer(transformers=[(&#x27;num&#x27;,\n","                                                                         Pipeline(steps=[(&#x27;imputer&#x27;,\n","                                                                                          SimpleImputer(strategy=&#x27;median&#x27;)),\n","                                                                                         (&#x27;scaler&#x27;,\n","                                                                                          StandardScaler())]),\n","                                                                         [&#x27;loan_amnt&#x27;,\n","                                                                          &#x27;interest_rate&#x27;,\n","                                                                          &#x27;annual_income&#x27;,\n","                                                                          &#x27;debt_to_income&#x27;,\n","                                                                          &#x27;delinq_2yrs&#x27;,\n","                                                                          &#x27;public_records&#x27;,\n","                                                                          &#x27;revolving_balance&#x27;,\n","                                                                          &#x27;total_acc&#x27;,\n","                                                                          &#x27;interest_receive&#x27;,\n","                                                                          &#x27;last_week_pay&#x27;,...\n","                                                                                          OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n","                                                                         [&#x27;loan_term&#x27;,\n","                                                                          &#x27;loan_grade&#x27;,\n","                                                                          &#x27;loan_subgrade&#x27;,\n","                                                                          &#x27;job_experience&#x27;,\n","                                                                          &#x27;home_ownership&#x27;,\n","                                                                          &#x27;income_verification_status&#x27;,\n","                                                                          &#x27;loan_purpose&#x27;,\n","                                                                          &#x27;state_code&#x27;,\n","                                                                          &#x27;application_type&#x27;])])),\n","                                       (&#x27;classifier&#x27;,\n","                                        RandomForestClassifier(random_state=42))]),\n","             param_grid={&#x27;classifier__max_depth&#x27;: [10, 20, 30],\n","                         &#x27;classifier__n_estimators&#x27;: [100, 200, 300]},\n","             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n","                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n","                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n","                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n","                                                                  (&#x27;scaler&#x27;,\n","                                                                   StandardScaler())]),\n","                                                  [&#x27;loan_amnt&#x27;, &#x27;interest_rate&#x27;,\n","                                                   &#x27;annual_income&#x27;,\n","                                                   &#x27;debt_to_income&#x27;,\n","                                                   &#x27;delinq_2yrs&#x27;,\n","                                                   &#x27;public_records&#x27;,\n","                                                   &#x27;revolving_balance&#x27;,\n","                                                   &#x27;total_acc&#x27;,\n","                                                   &#x27;interest_receive&#x27;,\n","                                                   &#x27;last_week_pay&#x27;,\n","                                                   &#x27;total_current_balance&#x27;,\n","                                                   &#x27;tot..._limit&#x27;]),\n","                                                 (&#x27;cat&#x27;,\n","                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n","                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n","                                                                  (&#x27;onehot&#x27;,\n","                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n","                                                  [&#x27;loan_term&#x27;, &#x27;loan_grade&#x27;,\n","                                                   &#x27;loan_subgrade&#x27;,\n","                                                   &#x27;job_experience&#x27;,\n","                                                   &#x27;home_ownership&#x27;,\n","                                                   &#x27;income_verification_status&#x27;,\n","                                                   &#x27;loan_purpose&#x27;, &#x27;state_code&#x27;,\n","                                                   &#x27;application_type&#x27;])])),\n","                (&#x27;classifier&#x27;, RandomForestClassifier(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n","                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n","                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n","                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n","                                 [&#x27;loan_amnt&#x27;, &#x27;interest_rate&#x27;, &#x27;annual_income&#x27;,\n","                                  &#x27;debt_to_income&#x27;, &#x27;delinq_2yrs&#x27;,\n","                                  &#x27;public_records&#x27;, &#x27;revolving_balance&#x27;,\n","                                  &#x27;total_acc&#x27;, &#x27;interest_receive&#x27;,\n","                                  &#x27;last_week_pay&#x27;, &#x27;total_current_balance&#x27;,\n","                                  &#x27;total_revolving_limit&#x27;]),\n","                                (&#x27;cat&#x27;,\n","                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n","                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n","                                                 (&#x27;onehot&#x27;,\n","                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n","                                 [&#x27;loan_term&#x27;, &#x27;loan_grade&#x27;, &#x27;loan_subgrade&#x27;,\n","                                  &#x27;job_experience&#x27;, &#x27;home_ownership&#x27;,\n","                                  &#x27;income_verification_status&#x27;, &#x27;loan_purpose&#x27;,\n","                                  &#x27;state_code&#x27;, &#x27;application_type&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;loan_amnt&#x27;, &#x27;interest_rate&#x27;, &#x27;annual_income&#x27;, &#x27;debt_to_income&#x27;, &#x27;delinq_2yrs&#x27;, &#x27;public_records&#x27;, &#x27;revolving_balance&#x27;, &#x27;total_acc&#x27;, &#x27;interest_receive&#x27;, &#x27;last_week_pay&#x27;, &#x27;total_current_balance&#x27;, &#x27;total_revolving_limit&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;loan_term&#x27;, &#x27;loan_grade&#x27;, &#x27;loan_subgrade&#x27;, &#x27;job_experience&#x27;, &#x27;home_ownership&#x27;, &#x27;income_verification_status&#x27;, &#x27;loan_purpose&#x27;, &#x27;state_code&#x27;, &#x27;application_type&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"]},"metadata":{},"execution_count":20}],"source":["grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n","grid_search.fit(X_train, y_train)"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rxE2viEqc5x4","executionInfo":{"status":"ok","timestamp":1716710356085,"user_tz":-330,"elapsed":3275,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"}},"outputId":"7437d6ab-3520-417d-9472-4ecb4d1fbf1e"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"asGBZxd7weAI","executionInfo":{"status":"ok","timestamp":1716710356086,"user_tz":-330,"elapsed":10,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"}},"outputId":"24b5beb6-982b-4478-f330-105868d59398"},"outputs":[{"output_type":"stream","name":"stdout","text":["Best Params: {'classifier__max_depth': 30, 'classifier__n_estimators': 200}\n","Best Score: 0.8221602204844348\n"]}],"source":["print('Best Params:', grid_search.best_params_)\n","print('Best Score:', grid_search.best_score_)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"mI9vt-OvKAkn","executionInfo":{"status":"ok","timestamp":1716710356086,"user_tz":-330,"elapsed":8,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"}}},"outputs":[],"source":["\n","# Use the best model from grid search\n","best_model = grid_search.best_estimator_"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"-fD_x4eZDk65","executionInfo":{"status":"ok","timestamp":1716710357858,"user_tz":-330,"elapsed":1780,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"}}},"outputs":[],"source":["# Predict on validation set\n","y_val_pred = best_model.predict(X_val)"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"onRRM7MbJ68s","executionInfo":{"status":"ok","timestamp":1716710357859,"user_tz":-330,"elapsed":43,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"}},"outputId":"42c59c7c-0f66-487a-cab6-696fa3b8ea6b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.8203380735175745\n","              precision    recall  f1-score   support\n","\n","           0       0.81      0.99      0.89     14083\n","           1       0.89      0.30      0.45      4552\n","\n","    accuracy                           0.82     18635\n","   macro avg       0.85      0.64      0.67     18635\n","weighted avg       0.83      0.82      0.78     18635\n","\n","Confusion Matrix:\n"," [[13912   171]\n"," [ 3177  1375]]\n"]}],"source":["# Validate the model\n","accuracy = accuracy_score(y_val, y_val_pred)\n","print('Accuracy:', accuracy)\n","print(classification_report(y_val, y_val_pred))\n","print('Confusion Matrix:\\n', confusion_matrix(y_val, y_val_pred))"]},{"cell_type":"code","source":["# Remove the prefix 'classifier__' from best_params_\n","best_params = {param.replace('classifier__', ''): value for param, value in grid_search.best_params_.items()}\n"],"metadata":{"id":"OHEzq4eo8FCS","executionInfo":{"status":"ok","timestamp":1716710828574,"user_tz":-330,"elapsed":416,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["# Train the final model with the best parameters on the entire training data\n","final_model = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('classifier', RandomForestClassifier(**best_params, random_state=42))\n","])"],"metadata":{"id":"9hCTNIOz6tbt","executionInfo":{"status":"ok","timestamp":1716710843510,"user_tz":-330,"elapsed":783,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":231},"id":"h9hzLhlu1cnl","executionInfo":{"status":"ok","timestamp":1716711389655,"user_tz":-330,"elapsed":535708,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"}},"outputId":"0f3974e8-35c3-4859-833b-d868bd2a6db7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(steps=[('preprocessor',\n","                 ColumnTransformer(transformers=[('num',\n","                                                  Pipeline(steps=[('imputer',\n","                                                                   SimpleImputer(strategy='median')),\n","                                                                  ('scaler',\n","                                                                   StandardScaler())]),\n","                                                  ['loan_amnt', 'interest_rate',\n","                                                   'annual_income',\n","                                                   'debt_to_income',\n","                                                   'delinq_2yrs',\n","                                                   'public_records',\n","                                                   'revolving_balance',\n","                                                   'total_acc',\n","                                                   'interest_receive',\n","                                                   'last_week_pay',\n","                                                   'total_current_balance',\n","                                                   'tot...\n","                                                  Pipeline(steps=[('imputer',\n","                                                                   SimpleImputer(strategy='most_frequent')),\n","                                                                  ('onehot',\n","                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n","                                                  ['loan_term', 'loan_grade',\n","                                                   'loan_subgrade',\n","                                                   'job_experience',\n","                                                   'home_ownership',\n","                                                   'income_verification_status',\n","                                                   'loan_purpose', 'state_code',\n","                                                   'application_type'])])),\n","                ('classifier',\n","                 RandomForestClassifier(max_depth=30, n_estimators=200,\n","                                        random_state=42))])"],"text/html":["<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n","                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n","                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n","                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n","                                                                  (&#x27;scaler&#x27;,\n","                                                                   StandardScaler())]),\n","                                                  [&#x27;loan_amnt&#x27;, &#x27;interest_rate&#x27;,\n","                                                   &#x27;annual_income&#x27;,\n","                                                   &#x27;debt_to_income&#x27;,\n","                                                   &#x27;delinq_2yrs&#x27;,\n","                                                   &#x27;public_records&#x27;,\n","                                                   &#x27;revolving_balance&#x27;,\n","                                                   &#x27;total_acc&#x27;,\n","                                                   &#x27;interest_receive&#x27;,\n","                                                   &#x27;last_week_pay&#x27;,\n","                                                   &#x27;total_current_balance&#x27;,\n","                                                   &#x27;tot...\n","                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n","                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n","                                                                  (&#x27;onehot&#x27;,\n","                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n","                                                  [&#x27;loan_term&#x27;, &#x27;loan_grade&#x27;,\n","                                                   &#x27;loan_subgrade&#x27;,\n","                                                   &#x27;job_experience&#x27;,\n","                                                   &#x27;home_ownership&#x27;,\n","                                                   &#x27;income_verification_status&#x27;,\n","                                                   &#x27;loan_purpose&#x27;, &#x27;state_code&#x27;,\n","                                                   &#x27;application_type&#x27;])])),\n","                (&#x27;classifier&#x27;,\n","                 RandomForestClassifier(max_depth=30, n_estimators=200,\n","                                        random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n","                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n","                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n","                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n","                                                                  (&#x27;scaler&#x27;,\n","                                                                   StandardScaler())]),\n","                                                  [&#x27;loan_amnt&#x27;, &#x27;interest_rate&#x27;,\n","                                                   &#x27;annual_income&#x27;,\n","                                                   &#x27;debt_to_income&#x27;,\n","                                                   &#x27;delinq_2yrs&#x27;,\n","                                                   &#x27;public_records&#x27;,\n","                                                   &#x27;revolving_balance&#x27;,\n","                                                   &#x27;total_acc&#x27;,\n","                                                   &#x27;interest_receive&#x27;,\n","                                                   &#x27;last_week_pay&#x27;,\n","                                                   &#x27;total_current_balance&#x27;,\n","                                                   &#x27;tot...\n","                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n","                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n","                                                                  (&#x27;onehot&#x27;,\n","                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n","                                                  [&#x27;loan_term&#x27;, &#x27;loan_grade&#x27;,\n","                                                   &#x27;loan_subgrade&#x27;,\n","                                                   &#x27;job_experience&#x27;,\n","                                                   &#x27;home_ownership&#x27;,\n","                                                   &#x27;income_verification_status&#x27;,\n","                                                   &#x27;loan_purpose&#x27;, &#x27;state_code&#x27;,\n","                                                   &#x27;application_type&#x27;])])),\n","                (&#x27;classifier&#x27;,\n","                 RandomForestClassifier(max_depth=30, n_estimators=200,\n","                                        random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n","                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n","                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n","                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n","                                 [&#x27;loan_amnt&#x27;, &#x27;interest_rate&#x27;, &#x27;annual_income&#x27;,\n","                                  &#x27;debt_to_income&#x27;, &#x27;delinq_2yrs&#x27;,\n","                                  &#x27;public_records&#x27;, &#x27;revolving_balance&#x27;,\n","                                  &#x27;total_acc&#x27;, &#x27;interest_receive&#x27;,\n","                                  &#x27;last_week_pay&#x27;, &#x27;total_current_balance&#x27;,\n","                                  &#x27;total_revolving_limit&#x27;]),\n","                                (&#x27;cat&#x27;,\n","                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n","                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n","                                                 (&#x27;onehot&#x27;,\n","                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n","                                 [&#x27;loan_term&#x27;, &#x27;loan_grade&#x27;, &#x27;loan_subgrade&#x27;,\n","                                  &#x27;job_experience&#x27;, &#x27;home_ownership&#x27;,\n","                                  &#x27;income_verification_status&#x27;, &#x27;loan_purpose&#x27;,\n","                                  &#x27;state_code&#x27;, &#x27;application_type&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;loan_amnt&#x27;, &#x27;interest_rate&#x27;, &#x27;annual_income&#x27;, &#x27;debt_to_income&#x27;, &#x27;delinq_2yrs&#x27;, &#x27;public_records&#x27;, &#x27;revolving_balance&#x27;, &#x27;total_acc&#x27;, &#x27;interest_receive&#x27;, &#x27;last_week_pay&#x27;, &#x27;total_current_balance&#x27;, &#x27;total_revolving_limit&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;loan_term&#x27;, &#x27;loan_grade&#x27;, &#x27;loan_subgrade&#x27;, &#x27;job_experience&#x27;, &#x27;home_ownership&#x27;, &#x27;income_verification_status&#x27;, &#x27;loan_purpose&#x27;, &#x27;state_code&#x27;, &#x27;application_type&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=30, n_estimators=200, random_state=42)</pre></div></div></div></div></div></div></div>"]},"metadata":{},"execution_count":33}],"source":["final_model.fit(X, y)"]},{"cell_type":"code","source":["# Prepare the test data\n","X_test = test_data.drop('ID', axis=1)"],"metadata":{"id":"ZmjvqVrn-tS8","executionInfo":{"status":"ok","timestamp":1716711520356,"user_tz":-330,"elapsed":596,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["# Predict on test data\n","test_predictions = final_model.predict(X_test)\n"],"metadata":{"id":"L2SLYX0A-xpi","executionInfo":{"status":"ok","timestamp":1716711535725,"user_tz":-330,"elapsed":3751,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","execution_count":36,"metadata":{"id":"a5zj5Lx11gN1","executionInfo":{"status":"ok","timestamp":1716711552929,"user_tz":-330,"elapsed":626,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"}}},"outputs":[],"source":["# Prepare submission file\n","submission = pd.DataFrame({\n","    'ID': test_data['ID'],\n","    'default': test_predictions\n","})"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"5z8vXrEK1674","executionInfo":{"status":"ok","timestamp":1716711560526,"user_tz":-330,"elapsed":643,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"}}},"outputs":[],"source":["submission.to_csv('/content/drive/MyDrive/Colab Notebooks/GreatLearning/Hackahon/Hackathon_25May2024/Sample_Submission.csv', index=False)"]},{"cell_type":"code","source":["print('Submission file created successfully.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B-l6YJBc-7Wt","executionInfo":{"status":"ok","timestamp":1716711572206,"user_tz":-330,"elapsed":432,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"}},"outputId":"0793bd7b-1f03-4ade-eaa6-2de63383a571"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Submission file created successfully.\n"]}]},{"cell_type":"markdown","source":["# New Section"],"metadata":{"id":"T3vSdKBsNKCo"}},{"cell_type":"code","source":["# Preprocess data and generate polynomial features\n","preprocessed_X_train = preprocessor.fit_transform(X_train)\n","preprocessed_X_val = preprocessor.transform(X_val)"],"metadata":{"id":"YUe32RroNVcB","executionInfo":{"status":"ok","timestamp":1716719818024,"user_tz":-330,"elapsed":1336,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n","X_poly_train = poly.fit_transform(preprocessed_X_train)\n","X_poly_val = poly.transform(preprocessed_X_val)"],"metadata":{"id":"dK6I7Wk1Nft5","executionInfo":{"status":"ok","timestamp":1716719820587,"user_tz":-330,"elapsed":819,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Apply SMOTE to balance the classes in the training set\n","smote = SMOTE(random_state=42)\n","X_resampled, y_resampled = smote.fit_resample(X_poly_train, y_train)"],"metadata":{"id":"5wYUcha7N3r6","executionInfo":{"status":"ok","timestamp":1716736148650,"user_tz":-330,"elapsed":16326158,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Define model candidates\n","models = {\n","    'RandomForest': RandomForestClassifier(random_state=42),\n","    'GradientBoosting': GradientBoostingClassifier(random_state=42),\n","    'XGBoost': XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n","    'LightGBM': LGBMClassifier(random_state=42)\n","}"],"metadata":{"id":"WZ2IDkgROGWU","executionInfo":{"status":"ok","timestamp":1716737493084,"user_tz":-330,"elapsed":7,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Perform GridSearchCV for each model\n","best_models = {}\n","for model_name, model in models.items():\n","    pipeline = Pipeline(steps=[\n","        ('classifier', model)\n","    ])\n","\n","    param_grid = {\n","        'RandomForest': {\n","            'classifier__n_estimators': [100, 200, 300],\n","            'classifier__max_depth': [10, 20, 30]\n","        },\n","        'GradientBoosting': {\n","            'classifier__n_estimators': [100, 200, 300],\n","            'classifier__learning_rate': [0.01, 0.1, 0.2],\n","            'classifier__max_depth': [3, 5, 7]\n","        },\n","        'XGBoost': {\n","            'classifier__n_estimators': [100, 200, 300],\n","            'classifier__learning_rate': [0.01, 0.1, 0.2],\n","            'classifier__max_depth': [3, 5, 7]\n","        },\n","        'LightGBM': {\n","            'classifier__n_estimators': [100, 200, 300],\n","            'classifier__learning_rate': [0.01, 0.1, 0.2],\n","            'classifier__max_depth': [10, 20, 30]\n","        }\n","    }"],"metadata":{"id":"bsOAufP0h7S_","executionInfo":{"status":"ok","timestamp":1716737528602,"user_tz":-330,"elapsed":832,"user":{"displayName":"JataShankar Poddar","userId":"12347990147516018454"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["grid_search = GridSearchCV(pipeline, param_grid[model_name], cv=5, scoring='accuracy')\n","grid_search.fit(X_resampled, y_resampled)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gqwMoxJhh91U","outputId":"34a2d535-ffcf-41a8-c589-58888d9f603c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 9.032474 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 603159\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4206\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 7.481227 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 585628\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4199\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.432494 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557974\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4172\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 9.163195 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 558709\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4178\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.594079 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557604\n","[LightGBM] [Info] Number of data points in the train set: 91140, number of used features: 4186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 9.357754 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 603159\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4206\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 9.010273 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 585628\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4199\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 8.688890 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557974\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4172\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 8.867527 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 558709\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4178\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 8.343377 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557604\n","[LightGBM] [Info] Number of data points in the train set: 91140, number of used features: 4186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 8.213693 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 603159\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4206\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.930928 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 585628\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4199\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.789558 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557974\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4172\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.218673 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 558709\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4178\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 8.285618 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557604\n","[LightGBM] [Info] Number of data points in the train set: 91140, number of used features: 4186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.633053 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 603159\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4206\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.764631 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 585628\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4199\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.012415 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557974\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4172\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.045696 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 558709\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4178\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.723913 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557604\n","[LightGBM] [Info] Number of data points in the train set: 91140, number of used features: 4186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.284235 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 603159\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4206\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.282605 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 585628\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4199\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.452393 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557974\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4172\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 8.187131 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 558709\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4178\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.742863 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557604\n","[LightGBM] [Info] Number of data points in the train set: 91140, number of used features: 4186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 8.063192 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 603159\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4206\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 8.469119 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 585628\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4199\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.559918 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557974\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4172\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 8.293129 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 558709\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4178\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 8.073823 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557604\n","[LightGBM] [Info] Number of data points in the train set: 91140, number of used features: 4186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 8.119847 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 603159\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4206\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.431633 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 585628\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4199\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.051005 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557974\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4172\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.636489 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 558709\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4178\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.855046 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557604\n","[LightGBM] [Info] Number of data points in the train set: 91140, number of used features: 4186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 5.728200 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 603159\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4206\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 5.859323 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 585628\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4199\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.252234 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557974\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4172\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.956820 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 558709\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4178\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.758762 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557604\n","[LightGBM] [Info] Number of data points in the train set: 91140, number of used features: 4186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 8.057703 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 603159\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4206\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.874711 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 585628\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4199\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 5.789549 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557974\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4172\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 5.736338 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 558709\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4178\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 5.642356 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557604\n","[LightGBM] [Info] Number of data points in the train set: 91140, number of used features: 4186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 5.946535 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 603159\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4206\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 8.294683 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 585628\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4199\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.326885 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557974\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4172\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.381858 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 558709\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4178\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.697057 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557604\n","[LightGBM] [Info] Number of data points in the train set: 91140, number of used features: 4186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 8.336607 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 603159\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4206\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 8.445667 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 585628\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4199\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.875670 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557974\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4172\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.049595 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 558709\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4178\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.745765 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557604\n","[LightGBM] [Info] Number of data points in the train set: 91140, number of used features: 4186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.674721 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 603159\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4206\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.985236 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 585628\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4199\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.852742 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557974\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4172\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.873752 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 558709\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4178\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.103369 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557604\n","[LightGBM] [Info] Number of data points in the train set: 91140, number of used features: 4186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.477916 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 603159\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4206\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 8.612241 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 585628\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4199\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.162561 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557974\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4172\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.320885 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 558709\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4178\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.603756 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557604\n","[LightGBM] [Info] Number of data points in the train set: 91140, number of used features: 4186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.957743 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 603159\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4206\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 8.202773 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 585628\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4199\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.312816 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557974\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4172\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 8.099851 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 558709\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4178\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.017945 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557604\n","[LightGBM] [Info] Number of data points in the train set: 91140, number of used features: 4186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.298682 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 603159\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4206\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.297443 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 585628\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4199\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 5.750698 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557974\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4172\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.733297 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 558709\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4178\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.423416 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557604\n","[LightGBM] [Info] Number of data points in the train set: 91140, number of used features: 4186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.447130 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 603159\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4206\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.325426 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 585628\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4199\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 5.909012 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557974\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4172\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 5.757948 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 558709\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4178\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.073366 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557604\n","[LightGBM] [Info] Number of data points in the train set: 91140, number of used features: 4186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.226894 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 603159\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4206\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.735820 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 585628\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4199\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 8.105565 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557974\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4172\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.309534 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 558709\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4178\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 5.859148 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557604\n","[LightGBM] [Info] Number of data points in the train set: 91140, number of used features: 4186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.597903 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 603159\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4206\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.782899 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 585628\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4199\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.613763 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557974\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4172\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.236829 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 558709\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4178\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.742569 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557604\n","[LightGBM] [Info] Number of data points in the train set: 91140, number of used features: 4186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.502371 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 603159\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4206\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 8.357442 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 585628\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4199\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 8.040389 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557974\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4172\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.937297 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 558709\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4178\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.717620 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557604\n","[LightGBM] [Info] Number of data points in the train set: 91140, number of used features: 4186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.985122 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 603159\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4206\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.123854 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 585628\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4199\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 8.363212 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557974\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4172\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.471894 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 558709\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4178\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 5.781736 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557604\n","[LightGBM] [Info] Number of data points in the train set: 91140, number of used features: 4186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.915593 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 603159\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4206\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.733644 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 585628\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4199\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.197778 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557974\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4172\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.351237 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 558709\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4178\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 5.979356 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557604\n","[LightGBM] [Info] Number of data points in the train set: 91140, number of used features: 4186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.567182 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 603159\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4206\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 4.847574 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 585628\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4199\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.170561 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557974\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4172\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.967994 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 558709\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4178\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 5.538140 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557604\n","[LightGBM] [Info] Number of data points in the train set: 91140, number of used features: 4186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.180712 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 603159\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4206\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.101237 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 585628\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4199\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.142160 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557974\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4172\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 5.763565 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 558709\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4178\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 5.506481 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557604\n","[LightGBM] [Info] Number of data points in the train set: 91140, number of used features: 4186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 5.401365 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 603159\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4206\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 5.873641 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 585628\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4199\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 5.120699 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557974\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4172\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 5.202407 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 558709\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4178\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.517893 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557604\n","[LightGBM] [Info] Number of data points in the train set: 91140, number of used features: 4186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.096676 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 603159\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4206\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 5.838136 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 585628\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4199\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.400477 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557974\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4172\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45569, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.407660 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 558709\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4178\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499995 -> initscore=-0.000022\n","[LightGBM] [Info] Start training from score -0.000022\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.122270 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 557604\n","[LightGBM] [Info] Number of data points in the train set: 91140, number of used features: 4186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 45570, number of negative: 45569\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.250769 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 603159\n","[LightGBM] [Info] Number of data points in the train set: 91139, number of used features: 4206\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n","[LightGBM] [Info] Start training from score 0.000022\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"toc_visible":true,"mount_file_id":"1I9SBlqWYejiXQyGC0-w35c-29CuQe1MW","authorship_tag":"ABX9TyMnpcNuQ95uQRbr2Qve1nq5"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}